# ğŸ¡ Pinica IA â€“ Intelligent Home Automation with Agents

> **Agent-based smart home system** using voice, computer vision, and local LLMs.  
> Your house **listens, sees, understands, and talks to you** â€“ intelligently.

---

## âœ¨ Overview

`pinica_ia` is a modular agent-based automation framework that integrates:

- ğŸ™ï¸ Audio capture and speech recognition using Whisper
- ğŸ‘ï¸ Vision-based scene detection using YOLOv8 (via OpenCV)
- ğŸ§  Natural language understanding and reasoning using Ollama + LLaMA3
- ğŸ—£ï¸ Natural voice responses using Facebook MMS-TTS
- ğŸ’¡ MQTT-based device control (in development)
- ğŸ“Š Optional Streamlit dashboard (in development)

---

## ğŸ§  Agent Architecture

Each key function is encapsulated as an **agent**, allowing for modular orchestration:

```
[ğŸ™ï¸ AudioAgent] â†’ Transcribe speech
        â”‚
        â–¼
[ğŸ§  LLM PlannerAgent (optional)] â†’ Plan actions
        â”‚
        â”œâ”€â–¶ [ğŸ‘ï¸ VisionAgent] (if vision is needed)
        â””â”€â–¶ [ğŸ§  LLMAgent] â†’ Generate response
                          â”‚
                          â–¼
                   [ğŸ—£ï¸ SpeechAgent]
```

---

## ğŸ“¦ Key Components

| Agent/Class       | Description                                                      |
|-------------------|------------------------------------------------------------------|
| `AudioAgent`      | Captures user speech and transcribes using Whisper              |
| `VisionAgent`     | Detects and describes scene objects using YOLOv8                |
| `LLMAgent`        | Sends text (and context) to Ollama LLM and returns responses    |
| `SpeechAgent`     | Converts LLM responses into voice using MMS-TTS                 |
| `main_async.py`   | Orchestrates agent interaction via asyncio loop                 |

---

## ğŸš€ How to Run

### 1. Clone the repository

```bash
git clone https://github.com/yourname/pinica_ia.git
cd pinica_ia
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Start services with Docker

```bash
docker-compose up -d
```

### 4. Configure rooms and camera access

Edit `configs/rooms.json`:

```json
{
  "living_room": {
    "mic_device": 1,
    "cameras": ["rtsp://user:password@192.168.1.10:554/stream1"],
    "mqtt_topic": "home/living_room"
  }
}
```

Edit `configs/secrets.json` with your camera credentials.

### 5. Run the assistant with agents

```bash
python app/main_async.py
```

---

## ğŸ“‚ Project Structure (after agent refactor)

```
pinica_ia/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main_async.py            # Async loop using agents
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ audio_agent.py       # Audio capture agent
â”‚   â”‚   â”œâ”€â”€ vision_agent.py      # Vision scene agent
â”‚   â”‚   â”œâ”€â”€ llm_agent.py         # LLM query agent
â”‚   â”‚   â””â”€â”€ speech_agent.py      # Text-to-speech agent
â”‚   â”œâ”€â”€ utils/                   # Whisper, YOLO, TTS helpers
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â”œâ”€â”€ rooms.json
â”‚   â”‚   â””â”€â”€ secrets.json
â”‚   â””â”€â”€ logs/
â”‚       â””â”€â”€ llm_speech.log       # Log of spoken outputs
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ mosquitto.conf
```

---

## ğŸ’¬ Example Commands

- "EstÃ¡ muito calor aqui" â†’ Turns on the air conditioning  
- "Estou indo dormir" â†’ Turns off lights and closes curtains  
- "Tem alguÃ©m na porta?" â†’ Uses camera to check and respond  
- "Qual a temperatura na cozinha?" â†’ Reads sensors and answers  

---

## ğŸ” Security

- Fully offline capable: LLM and TTS run locally  
- Camera credentials are isolated in `secrets.json`  
- Future support for encryption and command authentication  

---

## ğŸ’¡ Credits & Inspiration

Inspired by JARVIS (Iron Man), Home Assistant, ESPHome, Ollama, and the dream of a **talking intelligent home**.
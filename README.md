
# ğŸ¡ Pinica IA â€“ Intelligent Home Assistant with Modular Agents

> **Local-first smart home system** with voice, vision, and language intelligence.  
> Your house **listens, sees, understands, speaks, searches â€” and now controls lights.**

---

## âœ¨ Overview

`pinica_ia` is a modular and agent-based home automation framework that integrates:

- ğŸ™ï¸ Real-time speech transcription with Whisper
- ğŸ‘ï¸ Vision detection using YOLOv8 (via OpenCV)
- ğŸ§  Local LLM-based reasoning using Ollama + Phi-4
- ğŸ—£ï¸ Natural speech responses using Facebook MMS-TTS
- ğŸŒ Web search agent via DuckDuckGo
- ğŸ’¡ Device control via **Home Assistant (Sonoff supported)**
- ğŸ“Š Optional UI with Django (in development)

---

## ğŸ§  Agent Architecture

Each function is encapsulated as an **independent agent**, orchestrated asynchronously:

```
[ğŸ™ï¸ AudioAgent] â†’ Captures & transcribes speech
         â”‚
         â–¼
[ğŸ§  IntentClassifierAgent] â†’ Detects wake word + classifies intent
         â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â–¼                            â–¼
[ğŸ‘ï¸ VisionAgent]       [ğŸŒ SearchAgent]
         â”‚                     â”‚
         â–¼                     â–¼
     Scene summary        Web search results
         â”‚                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
           [ğŸ§  LLMAgent] â†’ Generates response
                â”‚
                â–¼
          [ğŸ—£ï¸ SpeechAgent] â†’ Speaks back
```

---

## ğŸ“¦ Core Components

| Agent/Class            | Description                                                                 |
|------------------------|-----------------------------------------------------------------------------|
| `AudioAgent`           | Captures microphone audio and transcribes using Whisper                    |
| `VisionAgent`          | Detects people/objects via camera and describes scene with YOLOv8          |
| `LLMAgent`             | Handles user interaction via prompt + context using Ollama (Phi-4, etc.)   |
| `SpeechAgent`          | Converts response text into audio using Facebook MMS-TTS                   |
| `SearchAgent`          | Searches the internet with DuckDuckGo and returns structured results       |
| `IntentClassifierAgent`| Uses a local LLM to detect if input has "coca" and which action to perform |
| `HomeAssistantUtils`   | Controls smart devices via Home Assistant REST API                         |
| `main.py`              | Async orchestration and command pipeline                                   |

---

## ğŸ§© Home Assistant Integration

Pinica IA now integrates with [Home Assistant](https://www.home-assistant.io/) to control devices like **Sonoff switches**.

- Uses the **local REST API** with long-lived token authentication.
- Devices must be configured in Home Assistant and mapped to rooms.
- New field `light_entity_id` added in `configs/rooms.json`:

```json
{
  "escritorio": {
    "mic_device": 4,
    "cameras": ["rtsp://..."],
    "mqtt_topic": "casa/escritorio",
    "light_entity_id": "switch.sonoff_10013abe9c_1"
  }
}
```

> Support for more Home Assistant services (climate, locks, etc.) coming soon.

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/yourname/pinica_ia.git
cd pinica_ia
```

### 2. Install requirements

```bash
pip install -r requirements.txt
```

### 3. Start support services (if using Docker)

```bash
docker-compose up -d
```

### 4. Configure your environment

Edit `configs/rooms.json`:

```json
{
  "sala": {
    "mic_device": 2,
    "cameras": ["rtsp://user:pass@192.168.1.20:554/stream"],
    "mqtt_topic": "home/sala",
    "light_entity_id": "switch.sonoff_sala"
  }
}
```

Update `.env` with your Home Assistant token:

```env
TOKEN=your_home_assistant_token
HASS_URL=http://localhost:8123
```

### 5. Run the assistant

```bash
python app/main_async.py
```

---

## ğŸ—£ï¸ Example Spoken Commands

| Transcription Example                               | Resulting Action                                            |
|-----------------------------------------------------|-------------------------------------------------------------|
| â€œCoca, what's in the camera?â€                       | VisionAgent runs, takes image, describes people/scene       |
| â€œKoka, turn on the light in the officeâ€             | Sends request to HA to turn on `switch.sonoff_...`          |
| â€œHey Coka, search the internet for pinica projectâ€  | DuckDuckGo search executed + summary spoken                 |
| â€œDesligar todas as luzes, Cocaâ€                     | (Upcoming) Multi-device HA control pipeline                 |
| â€œFinalize assistant, Cocaâ€                          | Assistant shuts down gracefully                             |

---

## ğŸ“‚ Project Structure

```
pinica_ia/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main_async.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ home_assistant.py  â† control via HA
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â”œâ”€â”€ rooms.json
â”‚   â”‚   â”œâ”€â”€ secrets.json
â”œâ”€â”€ notebooks/
â”œâ”€â”€ .env
â””â”€â”€ requirements.txt
```

---

## ğŸ” Privacy & Wake Word

- Assistant only responds if a variation of â€œcocaâ€ is heard (e.g., â€œkokaâ€, â€œcokaâ€, â€œkoukaâ€).
- All processing is done locally unless a web search is required.
- Searches and audio logs are saved in separate folders for auditability.

---

## ğŸ§  Powered By

- [Whisper](https://github.com/openai/whisper)
- [Ollama](https://ollama.com/)
- [YOLOv8](https://github.com/ultralytics/ultralytics)
- [DuckDuckGo Search API](https://duckduckgo.com)
- [MMS-TTS](https://github.com/facebookresearch/fairseq/tree/main/examples/mms)
- [Home Assistant](https://www.home-assistant.io/)

---

## ğŸ“˜ License

MIT Â© 2025 â€“ Developed by Nielsen Castelo Damasceno Dantas & contributors
